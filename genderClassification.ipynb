{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First make sure to install ffmpeg for audio processing here is a link on how to install\n",
    "- https://phoenixnap.com/kb/ffmpeg-windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import warnings\n",
    "import shutil\n",
    "import pickle\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminal Configuration\n",
    "Run this to avoid warnings being written in the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "\n",
    "functions used later in the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def get_files_from_paths(females_path, males_path):\n",
    "    females = [ os.path.join(females_path, f) for f in os.listdir(females_path) ]\n",
    "    males   = [ os.path.join(males_path, f) for f in os.listdir(males_path) ]\n",
    "    files   = females + males\n",
    "    return files\n",
    "\n",
    "\n",
    "def save_gmm(gmm, name):\n",
    "    path = os.getcwd()\n",
    "    filename = os.path.join(path, f\"{name}.gmm\")\n",
    "\n",
    "    with open(filename, 'wb') as gmm_file:\n",
    "        pickle.dump(gmm, gmm_file)\n",
    "    print (\"SAVING\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Splitting\n",
    "### Only run this if you dont have the dataset already split in `data` in `audios` folder\n",
    "We split The Data into 20% testing and 80% training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.2 #20% testing\n",
    "random_seed=42\n",
    "\n",
    "input_path = 'audios/dataset'\n",
    "output_path = 'audios/data'  \n",
    "\n",
    "females_path = os.path.join(input_path, 'females')\n",
    "males_path = os.path.join(input_path, 'males')\n",
    "\n",
    "# Create output directories\n",
    "output_train_path1 = os.path.join(output_path, 'TrainingData', 'females')\n",
    "output_test_path1 = os.path.join(output_path, 'TestingData', 'females')\n",
    "os.makedirs(output_train_path1, exist_ok=True)\n",
    "os.makedirs(output_test_path1, exist_ok=True)\n",
    "\n",
    "# Split and move female data\n",
    "females_files = [os.path.join(females_path, f) for f in os.listdir(females_path)]\n",
    "females_train, females_test = train_test_split(females_files, test_size=test_size, random_state=random_seed)\n",
    "\n",
    "for file_path in females_train:\n",
    "    shutil.copy(file_path, os.path.join(output_train_path1, os.path.basename(file_path)))\n",
    "for file_path in females_test:\n",
    "    shutil.copy(file_path, os.path.join(output_test_path1, os.path.basename(file_path)))\n",
    "\n",
    "output_train_path2 = os.path.join(output_path, 'TrainingData', 'males')\n",
    "output_test_path2 = os.path.join(output_path, 'TestingData', 'males')\n",
    "os.makedirs(output_train_path2, exist_ok=True)\n",
    "os.makedirs(output_test_path2, exist_ok=True)\n",
    "\n",
    "# Split and move female data\n",
    "males_files = [os.path.join(males_path, f) for f in os.listdir(males_path)]\n",
    "males_train, males_test = train_test_split(males_files, test_size=test_size, random_state=random_seed)\n",
    "\n",
    "for file_path in males_train:\n",
    "    shutil.copy(file_path, os.path.join(output_train_path2, os.path.basename(file_path)))\n",
    "for file_path in males_test:\n",
    "    shutil.copy(file_path, os.path.join(output_test_path2, os.path.basename(file_path)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features From Signal Using MFCC\n",
    "\n",
    "We use the following python_speech_features to pull out features from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to load the signal,samplerate from audio path\n",
    "\n",
    "def getSignalnRate(file_path):\n",
    "    signal, sample_rate = librosa.load(file_path, sr=None)\n",
    "    return sample_rate,signal\n",
    "\n",
    "\"\"\"\n",
    "(audio) The audio signal from which to compute features.\n",
    "(rate) The samplerate of the signal we are working with.\n",
    "(winlen) The length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "(winstep) The step between successive windows in seconds.Default is 0.01s (10 milliseconds)\n",
    "(numcep) The number of cepstrum to return. Default 13.\n",
    "(nfilt) The number of filters in the filterbank.# Default is 26.\n",
    "(nfft) The FFT size. Default is 512.\n",
    "(appendEnergy) If true, the zeroth cepstral coefficient is replaced with the log of the total frame energy. \n",
    "\n",
    "(deltas) capture the rate of change of the MFCCs over time, providing information about the dynamics of the audio signal.\n",
    "\"\"\"\n",
    "\n",
    "def extract_features(audio_path):\n",
    "    rate, audio  = getSignalnRate(audio_path)\n",
    "    mfcc_feature = mfcc(audio,rate,winlen=0.05, winstep=0.01,numcep= 13,nfilt= 30,nfft= 1024,appendEnergy = True)\n",
    "    mfcc_feature  = preprocessing.scale(mfcc_feature)\n",
    "    deltas        = delta(mfcc_feature, 2)\n",
    "    double_deltas = delta(deltas, 2)\n",
    "    combined      = np.hstack((mfcc_feature, deltas, double_deltas))\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "Then We Train the GMM model on the training data and save the model to load them in the SVC for Testing \n",
    "(if you have files `females.gmm` and `males.gmm` then no need to train as its already trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "females_training_path = \"audios/data/TrainingData/females\"\n",
    "males_training_path   = \"audios/data/TrainingData/males\"\n",
    "\n",
    "def Train():\n",
    "    files = get_files_from_paths(females_training_path,\n",
    "                                            males_training_path)\n",
    "    print(\"Files Loaded For Training =\"+ str(len(files)))\n",
    "    # collect voice features\n",
    "    features = {\"female\" : np.asarray(()), \"male\" : np.asarray(())}\n",
    "    \n",
    "    for file in files:\n",
    "        print(\"Training\", \":\", os.path.basename(file)))\n",
    "        print(features[\"female\"].shape, features[\"male\"].shape)\n",
    "        # extract MFCC & delta MFCC features from audio\n",
    "        try: \n",
    "            vector  = extract_features(file)\n",
    "            spk_gmm = hmm.GaussianHMM(n_components=16)      \n",
    "            spk_gmm.fit(vector)\n",
    "            spk_vec = spk_gmm.means_\n",
    "            \n",
    "            gender = os.path.basename(os.path.dirname(file))[:-1]\n",
    "            print(gender)\n",
    "            if features[gender].size == 0:  features[gender] = spk_vec\n",
    "            else                         :  features[gender] = np.vstack((features[gender], spk_vec))\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    save_gmm(features[\"female\"], \"females\")\n",
    "    save_gmm(features[\"male\"],   \"males\")\n",
    "\n",
    "\n",
    "# Start the training process\n",
    "Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing\n",
    "\n",
    "We Test the model on the testing data and we evalute our SVC model (if you have the `svm_model` file that means its already been tested,saved and ready for inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "females_testing_path = \"audios/data/TestingData/females\"\n",
    "males_testing_path = \"audios/data/TestingData/males\"\n",
    "\n",
    "females_model_path = \"females.gmm\"\n",
    "males_model_path = \"males.gmm\"\n",
    "\n",
    "# load models\n",
    "females_gmm = pickle.load(open(females_model_path, 'rb'))\n",
    "males_gmm   = pickle.load(open(males_model_path, 'rb'))\n",
    "\n",
    "# Data split\n",
    "X_train = np.vstack((females_gmm, males_gmm))\n",
    "y_train = np.hstack(( -1 * np.ones(females_gmm.shape[0]), np.ones(males_gmm.shape[0])))\n",
    "\n",
    "# clear the NaN values with mean of cols\n",
    "df = pd.DataFrame(X_train)\n",
    "df_new = df.fillna(df.mean())\n",
    "X_train = df_new\n",
    "\n",
    "# SVM training on gmm output and gender labels\n",
    "clf = SVC(kernel = 'rbf', probability=True) #nfham\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# SVM testing\n",
    "def Test():\n",
    "    error = 0\n",
    "    total_sample = 0    \n",
    "\n",
    "    files = get_files_from_paths(females_testing_path, males_testing_path)\n",
    "    for file in files:\n",
    "        total_sample += 1\n",
    "        print(\" TESTING\", \":\", file)\n",
    "\n",
    "        try: \n",
    "            # extract features\n",
    "            vector = extract_features(file)\n",
    "            # generate gaussian mixture models\n",
    "            spk_gmm = hmm.GaussianHMM(n_components=16)      \n",
    "            spk_gmm.fit(vector)\n",
    "            spk_vec = spk_gmm.means_\n",
    "            if sum(clf.predict(spk_vec)) > 0 : sc =  1\n",
    "            else                                       : sc = -1\n",
    "            genders = {-1: \"female\", 1: \"male\"}\n",
    "            winner = genders[sc]\n",
    "            expected_gender = os.path.basename(os.path.dirname(file))[:-1]\n",
    "            print(expected_gender)\n",
    "            \n",
    "            print(\"actual gender\",\":\", expected_gender)\n",
    "            print(\"identification\", \":\", winner)\n",
    "\n",
    "            if winner != expected_gender: error += 1\n",
    "            print(\"----------------------------------------------------\")\n",
    "\n",
    "\n",
    "        except : print(\"Error\")           \n",
    "    accuracy = ( float(total_sample - error) / float(total_sample) ) * 100\n",
    "    accuracy_msg = \"Model Accuracy = \" + str(round(accuracy, 3)) + \"%\"\n",
    "    print(accuracy_msg)  \n",
    "\n",
    "\n",
    "\n",
    "# Start The Testing Process\n",
    "Test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Saving\n",
    "\n",
    "Save the model for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, 'svm_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference\n",
    "\n",
    "Now we can test the model with custom input after testing and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "clf = joblib.load(\"svm_model.joblib\")\n",
    "\n",
    "# Model Inference With Custom input \n",
    "def Infer(path_to_custom_file):\n",
    "    try:\n",
    "        vector = extract_features(path_to_custom_file)\n",
    "        spk_gmm = hmm.GaussianHMM(n_components=16)      \n",
    "        spk_gmm.fit(vector)\n",
    "\n",
    "        spk_vec = spk_gmm.means_\n",
    "        prediction = clf.predict(spk_vec)\n",
    "\n",
    "        if sum(prediction) > 0:\n",
    "            gender = \"male\"\n",
    "        else:\n",
    "            gender = \"female\"\n",
    "\n",
    "        print(gender)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "\n",
    "# Start The inference Process paste in quotes the file path from current directory\n",
    "Infer(\"custom-audio/test.m4a\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
